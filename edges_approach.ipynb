{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pke5hB7S-OxS",
        "outputId": "1d7b629d-d54a-44b9-b324-997cae7c34e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: 31299 edges, 1912 nodes with features, 1912 target rows\n",
            "[ID match] Using targets column 'new_id' (overlap=1912); id=0\n",
            "Edge feature matrix: 31299 edges × 1449 features\n",
            "Graph: |V|=1912, |E|=31299\n",
            "[coverage] edges with source in targets: ~100.0%, dest in targets: ~100.0%\n",
            "Prototypes selected (improved): 50\n",
            "\n",
            "=== MODE SUMMARY ===\n",
            "          mode  prototypes   mean_q    std_q  median_q  mean_q_rg\n",
            "       C_mixed          10 0.548340 0.284942  0.618491   0.005572\n",
            "B_multi_binary          10 0.387158 0.200158  0.346574   0.004862\n",
            "     D_nominal          10 0.355563 0.168741  0.346574   0.004302\n",
            "      A_binary          10 0.195904 0.166322  0.259930   0.001273\n",
            "\n",
            "=== BEST PROTOTYPES (top 20 by q) ===\n",
            "          mode prototype        q     q_rg  rho  sigma  n_out  n_binary  n_nominal\n",
            "       C_mixed       314 1.039721 0.000291    2      1      2         2          4\n",
            "       C_mixed       364 0.693147 0.000300    2      1      2         2          4\n",
            "B_multi_binary       943 0.693147 0.000148    2      1      2         6          0\n",
            "       C_mixed       834 0.693147 0.000278    2      1      2         2          4\n",
            "       C_mixed       943 0.693147 0.000330    2      1      2         2          4\n",
            "     D_nominal       314 0.693147 0.000257    2      1      2         0          4\n",
            "       C_mixed       826 0.645200 0.000701    6      3      6         2          4\n",
            "B_multi_binary       151 0.591781 0.000242    4      1      4         6          0\n",
            "       C_mixed       151 0.591781 0.000477    4      1      4         2          4\n",
            "B_multi_binary       791 0.519860 0.000346    4      1      4         6          0\n",
            "       C_mixed       791 0.519860 0.000673    4      1      4         2          4\n",
            "B_multi_binary       826 0.501359 0.000329    6      2      6         6          0\n",
            "     D_nominal       826 0.442468 0.000600    6      3      6         0          4\n",
            "     D_nominal       151 0.431523 0.000404    4      3      4         0          4\n",
            "     D_nominal       791 0.346574 0.000605    4      1      4         0          4\n",
            "      A_binary       151 0.346574 0.000072    4      1      4         2          0\n",
            "     D_nominal       364 0.346574 0.000266    2      1      2         0          4\n",
            "B_multi_binary       364 0.346574 0.000218    2      1      2         6          0\n",
            "     D_nominal       943 0.346574 0.000296    2      1      2         0          4\n",
            "      A_binary       943 0.346574 0.000034    2      1      2         2          0\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import json\n",
        "from collections import Counter, deque\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "_EPS = 1e-12\n",
        "\n",
        "PROTOTYPE_SELECTION = {\n",
        "    \"mode\": \"improved\",        # \"original\" (all nodes) or \"improved\" (degree + max-min distance)\n",
        "    \"max_prototypes\": 50,      # l < n\n",
        "    \"quality_threshold\": -1.0, # disable early-stop while debugging (set >0 later)\n",
        "    \"patience_k\": 8,\n",
        "    \"distance_cutoff\": 4\n",
        "}\n",
        "\n",
        "COMPARE_R_TO_GLOBAL = True     # q(R, G) vs global edges (paper's original ablation)\n",
        "N_RHO_LIMIT = None              # Optional cap for ρ per prototype (e.g., 300)\n",
        "\n",
        "# =========================\n",
        "# Load Twitch PT data\n",
        "# =========================\n",
        "edges = pd.read_csv(\"edges.csv\")\n",
        "with open(\"features.json\", \"r\") as f:\n",
        "    node_features = json.load(f)\n",
        "targets = pd.read_csv(\"target.csv\")\n",
        "\n",
        "# normalize id types\n",
        "edges[\"from\"] = edges[\"from\"].astype(str)\n",
        "edges[\"to\"]   = edges[\"to\"].astype(str)\n",
        "if \"id\" in targets.columns:     targets[\"id\"]     = targets[\"id\"].astype(str)\n",
        "if \"new_id\" in targets.columns: targets[\"new_id\"] = targets[\"new_id\"].astype(str)\n",
        "\n",
        "print(f\"Loaded: {len(edges)} edges, {len(node_features)} nodes with features, {len(targets)} target rows\")\n",
        "\n",
        "# =========================\n",
        "# Detect correct target ID column\n",
        "# =========================\n",
        "edge_nodes = set(edges[\"from\"]).union(set(edges[\"to\"]))\n",
        "cand_cols = [c for c in [\"id\", \"new_id\"] if c in targets.columns]\n",
        "\n",
        "def _overlap(col):\n",
        "    return len(edge_nodes.intersection(set(targets[col].astype(str))))\n",
        "\n",
        "if not cand_cols:\n",
        "    raise RuntimeError(\"target.csv must contain 'id' or 'new_id' column.\")\n",
        "\n",
        "best_col    = max(cand_cols, key=_overlap)\n",
        "best_overlap = _overlap(best_col)\n",
        "alt_col      = None\n",
        "alt_overlap  = 0\n",
        "if len(cand_cols) == 2:\n",
        "    alt_col = (set(cand_cols) - {best_col}).pop()\n",
        "    alt_overlap = _overlap(alt_col)\n",
        "\n",
        "print(f\"[ID match] Using targets column '{best_col}' (overlap={best_overlap}); \"\n",
        "      f\"{alt_col+'='+str(alt_overlap) if alt_col else ''}\")\n",
        "\n",
        "# Build a fast lookup by chosen ID column\n",
        "targets[\"_key\"] = targets[best_col].astype(str)\n",
        "\n",
        "# Keep essential fields; fill missing numerics with NaN, binaries with 0\n",
        "for col in [\"mature\", \"partner\", \"days\", \"views\"]:\n",
        "    if col not in targets.columns:\n",
        "        raise RuntimeError(f\"target.csv missing required column '{col}'\")\n",
        "targets[\"mature\"]  = targets[\"mature\"].fillna(0).astype(int)\n",
        "targets[\"partner\"] = targets[\"partner\"].fillna(0).astype(int)\n",
        "targets[\"days\"]    = pd.to_numeric(targets[\"days\"], errors=\"coerce\")\n",
        "targets[\"views\"]   = pd.to_numeric(targets[\"views\"], errors=\"coerce\")\n",
        "\n",
        "t_by_id = {row[\"_key\"]: row for _, row in targets.iterrows()}\n",
        "\n",
        "# =========================\n",
        "# Build edge feature matrix (union of endpoint feature sets)\n",
        "# =========================\n",
        "def edge_feature_union(i, j):\n",
        "    fi = node_features.get(i, [])\n",
        "    fj = node_features.get(j, [])\n",
        "    return list(set(fi) | set(fj))\n",
        "\n",
        "edge_feature_dict = { (r[\"from\"], r[\"to\"]): edge_feature_union(r[\"from\"], r[\"to\"])\n",
        "                      for _, r in edges.iterrows() }\n",
        "\n",
        "all_codes = sorted({c for feats in edge_feature_dict.values() for c in feats})\n",
        "edge_features = pd.DataFrame(\n",
        "    0,\n",
        "    index=pd.MultiIndex.from_tuples(edge_feature_dict.keys(), names=[\"i\", \"j\"]),\n",
        "    columns=all_codes\n",
        ")\n",
        "for (i, j), feats in edge_feature_dict.items():\n",
        "    edge_features.loc[(i, j), feats] = 1\n",
        "\n",
        "print(f\"Edge feature matrix: {edge_features.shape[0]} edges × {edge_features.shape[1]} features\")\n",
        "\n",
        "# =========================\n",
        "# Global stats for target binning\n",
        "# =========================\n",
        "# Only use rows with non-null numerics for quantiles/means\n",
        "views_series = targets[\"views\"].dropna()\n",
        "days_series  = targets[\"days\"].dropna()\n",
        "\n",
        "# If everything is NaN (bad CSV), avoid crash\n",
        "if views_series.empty: views_series = pd.Series([0.0])\n",
        "if days_series.empty:  days_series  = pd.Series([0.0])\n",
        "\n",
        "views_q1, views_q2 = views_series.quantile([0.33, 0.66])\n",
        "days_q1, days_q2   = days_series.quantile([0.33, 0.66])\n",
        "mean_days          = float(days_series.mean())\n",
        "\n",
        "def _bands_from_val(val, q1, q2, low=\"low\", mid=\"medium\", hi=\"high\"):\n",
        "    if pd.isna(val):\n",
        "        return \"unknown\"\n",
        "    if val < q1:\n",
        "        return low\n",
        "    elif val < q2:\n",
        "        return mid\n",
        "    else:\n",
        "        return hi\n",
        "\n",
        "def _age_band(days_val):\n",
        "    if pd.isna(days_val):\n",
        "        return \"unknown\"\n",
        "    if days_val < days_q1:\n",
        "        return \"young\"\n",
        "    elif days_val < days_q2:\n",
        "        return \"mid\"\n",
        "    else:\n",
        "        return \"old\"\n",
        "\n",
        "def _get_row(node_id: str):\n",
        "    return t_by_id.get(node_id, None)\n",
        "\n",
        "# =========================\n",
        "# Derive *edge* targets from both endpoints\n",
        "# =========================\n",
        "def derive_edge_targets(i: str, j: str, row_vec: pd.Series):\n",
        "    total_value = float(row_vec.sum())\n",
        "\n",
        "    si = _get_row(i)\n",
        "    sj = _get_row(j)\n",
        "\n",
        "    # source\n",
        "    mature_i   = int(si[\"mature\"])  if si is not None else 0\n",
        "    partner_i  = int(si[\"partner\"]) if si is not None else 0\n",
        "    days_i     = float(si[\"days\"])  if si is not None else np.nan\n",
        "    views_i    = float(si[\"views\"]) if si is not None else np.nan\n",
        "    highact_i  = int((not pd.isna(days_i)) and (days_i > mean_days))\n",
        "    views_i_b  = _bands_from_val(views_i, views_q1, views_q2)\n",
        "    age_i_b    = _age_band(days_i)\n",
        "\n",
        "    # dest\n",
        "    mature_j   = int(sj[\"mature\"])  if sj is not None else 0\n",
        "    partner_j  = int(sj[\"partner\"]) if sj is not None else 0\n",
        "    days_j     = float(sj[\"days\"])  if sj is not None else np.nan\n",
        "    views_j    = float(sj[\"views\"]) if sj is not None else np.nan\n",
        "    highact_j  = int((not pd.isna(days_j)) and (days_j > mean_days))\n",
        "    views_j_b  = _bands_from_val(views_j, views_q1, views_q2)\n",
        "    age_j_b    = _age_band(days_j)\n",
        "\n",
        "    return {\n",
        "        # binary (both endpoints)\n",
        "        \"ExplicitLanguage_src\": mature_i,\n",
        "        \"ExplicitLanguage_dst\": mature_j,\n",
        "        \"Partner_src\": partner_i,\n",
        "        \"Partner_dst\": partner_j,\n",
        "        \"HighActivity_src\": highact_i,\n",
        "        \"HighActivity_dst\": highact_j,\n",
        "\n",
        "        # nominal (both endpoints)\n",
        "        \"ViewsBand_src\": views_i_b,\n",
        "        \"ViewsBand_dst\": views_j_b,\n",
        "        \"AgeBand_src\":   age_i_b,\n",
        "        \"AgeBand_dst\":   age_j_b,\n",
        "\n",
        "        # helper\n",
        "        \"TotalValue\": total_value\n",
        "    }\n",
        "\n",
        "# =========================\n",
        "# Build DiGraph with edge data\n",
        "# =========================\n",
        "G = nx.DiGraph()\n",
        "found_src = found_dst = 0\n",
        "\n",
        "for (i, j), row in edge_features.iterrows():\n",
        "    tdict = derive_edge_targets(i, j, row)\n",
        "    G.add_edge(i, j, features=row.to_dict(), **tdict)\n",
        "    if i in t_by_id: found_src += 1\n",
        "    if j in t_by_id: found_dst += 1\n",
        "\n",
        "print(f\"Graph: |V|={G.number_of_nodes()}, |E|={G.number_of_edges()}\")\n",
        "print(f\"[coverage] edges with source in targets: ~{found_src/len(edge_features):.1%}, \"\n",
        "      f\"dest in targets: ~{found_dst/len(edge_features):.1%}\")\n",
        "\n",
        "# =========================\n",
        "# Quality (Weighted KL) on edges\n",
        "# =========================\n",
        "def _dist(vals):\n",
        "    n = len(vals)\n",
        "    if n == 0:\n",
        "        return {}\n",
        "    c = Counter(vals)\n",
        "    return {k: v / n for k, v in c.items()}\n",
        "\n",
        "def wkl_quality_edges(S_edges, R_edges, binary_attrs, nominal_attrs):\n",
        "    nS, nR = len(S_edges), len(R_edges)\n",
        "    if nS == 0 or nR == 0:\n",
        "        return 0.0\n",
        "    qsum = 0.0\n",
        "\n",
        "    # Binary: ensure both 0 and 1 are considered\n",
        "    for attr in binary_attrs:\n",
        "        P_S = _dist([d[attr] for _, _, d in S_edges])\n",
        "        P_R = _dist([d[attr] for _, _, d in R_edges])\n",
        "        for y in (0, 1):\n",
        "            ps = P_S.get(y, _EPS)\n",
        "            pr = P_R.get(y, _EPS)\n",
        "            qsum += ps * math.log(ps / pr)\n",
        "\n",
        "    # Nominal: domain from both\n",
        "    for attr in nominal_attrs:\n",
        "        P_S = _dist([d[attr] for _, _, d in S_edges])\n",
        "        P_R = _dist([d[attr] for _, _, d in R_edges])\n",
        "        dom = set(P_S) | set(P_R)\n",
        "        for y in dom:\n",
        "            ps = P_S.get(y, _EPS)\n",
        "            pr = P_R.get(y, _EPS)\n",
        "            qsum += ps * math.log(ps / pr)\n",
        "\n",
        "    return (nS / nR) * qsum\n",
        "\n",
        "def _rank_out_edges_for_proto(G, proto):\n",
        "    edges_list = [(u, v, d) for u, v, d in G.out_edges(proto, data=True)]\n",
        "    # sort by TotalValue descending\n",
        "    edges_list.sort(key=lambda x: x[2][\"TotalValue\"], reverse=True)\n",
        "    return edges_list\n",
        "\n",
        "# =========================\n",
        "# Modes (≥2 nominal vars included)\n",
        "# =========================\n",
        "MODES = {\n",
        "    \"A_binary\": {\n",
        "        \"binary\": [\"ExplicitLanguage_src\", \"ExplicitLanguage_dst\"],\n",
        "        \"nominal\": []\n",
        "    },\n",
        "    \"B_multi_binary\": {\n",
        "        \"binary\": [\n",
        "            \"ExplicitLanguage_src\", \"ExplicitLanguage_dst\",\n",
        "            \"Partner_src\", \"Partner_dst\",\n",
        "            \"HighActivity_src\", \"HighActivity_dst\"\n",
        "        ],\n",
        "        \"nominal\": []\n",
        "    },\n",
        "    \"C_mixed\": {\n",
        "        \"binary\": [\"ExplicitLanguage_src\", \"ExplicitLanguage_dst\"],\n",
        "        \"nominal\": [\"ViewsBand_src\", \"ViewsBand_dst\", \"AgeBand_src\", \"AgeBand_dst\"]\n",
        "    },\n",
        "    \"D_nominal\": {\n",
        "        \"binary\": [],\n",
        "        \"nominal\": [\"ViewsBand_src\", \"ViewsBand_dst\", \"AgeBand_src\", \"AgeBand_dst\"]\n",
        "    },\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Find best q for a prototype\n",
        "#   - choose ρ by maximizing q(R, GLOBAL or out-edges)\n",
        "#   - choose σ by maximizing q(S, R)\n",
        "# =========================\n",
        "def find_best_q_for_prototype(G, proto, binary_attrs, nominal_attrs, global_edges_cache):\n",
        "    ranked = _rank_out_edges_for_proto(G, proto)\n",
        "    if len(ranked) < 2:\n",
        "        return None\n",
        "\n",
        "    baseline = global_edges_cache if COMPARE_R_TO_GLOBAL else ranked\n",
        "\n",
        "    best_rho, best_q_rg = 0, -float(\"inf\")\n",
        "    max_rho = len(ranked) if N_RHO_LIMIT is None else min(N_RHO_LIMIT, len(ranked))\n",
        "    for rho in range(2, max_rho + 1):\n",
        "        R = ranked[:rho]\n",
        "        q_rg = wkl_quality_edges(R, baseline, binary_attrs, nominal_attrs)\n",
        "        if q_rg > best_q_rg:\n",
        "            best_q_rg = q_rg\n",
        "            best_rho = rho\n",
        "\n",
        "    R_best = ranked[:best_rho]\n",
        "    best_sigma, best_q_sr = 0, -float(\"inf\")\n",
        "    for sigma in range(1, best_rho):\n",
        "        S = R_best[:sigma]\n",
        "        q_sr = wkl_quality_edges(S, R_best, binary_attrs, nominal_attrs)\n",
        "        if q_sr > best_q_sr:\n",
        "            best_q_sr = q_sr\n",
        "            best_sigma = sigma\n",
        "\n",
        "    return {\n",
        "        \"prototype\": proto,\n",
        "        \"rho\": best_rho,\n",
        "        \"sigma\": best_sigma,\n",
        "        \"q\": best_q_sr,\n",
        "        \"n_out\": len(ranked),\n",
        "        \"q_rg\": best_q_rg\n",
        "    }\n",
        "\n",
        "# =========================\n",
        "# Prototype selection\n",
        "# =========================\n",
        "def select_prototypes(G):\n",
        "    nodes = list(G.nodes())\n",
        "    if PROTOTYPE_SELECTION[\"mode\"] == \"original\":\n",
        "        return nodes\n",
        "\n",
        "    l = PROTOTYPE_SELECTION[\"max_prototypes\"]\n",
        "    # Start with highest-degree node\n",
        "    degs = {u: G.degree(u) for u in nodes}\n",
        "    first = max(degs, key=degs.get)\n",
        "    selected = [first]\n",
        "    remaining = set(nodes) - {first}\n",
        "\n",
        "    # Use undirected view; bounded all-pairs shortest paths\n",
        "    UG = G.to_undirected(as_view=True)\n",
        "    spl = dict(nx.all_pairs_shortest_path_length(UG, cutoff=PROTOTYPE_SELECTION[\"distance_cutoff\"]))\n",
        "\n",
        "    while len(selected) < l and remaining:\n",
        "        best_node, best_min = None, -1\n",
        "        for cand in list(remaining):\n",
        "            cand_map = spl.get(cand, {})\n",
        "            dists = [cand_map.get(s, np.inf) for s in selected]\n",
        "            m = min(dists) if dists else 0\n",
        "            if (m > best_min) or (m == best_min and degs.get(cand, 0) > degs.get(best_node, 0)):\n",
        "                best_node, best_min = cand, m\n",
        "        if best_node is None:\n",
        "            break\n",
        "        selected.append(best_node)\n",
        "        remaining.remove(best_node)\n",
        "\n",
        "    return selected\n",
        "\n",
        "# =========================\n",
        "# Main loop\n",
        "# =========================\n",
        "global_edges = [(u, v, d) for u, v, d in G.edges(data=True)]\n",
        "prototypes = select_prototypes(G)\n",
        "print(f\"Prototypes selected ({PROTOTYPE_SELECTION['mode']}): {len(prototypes)}\")\n",
        "\n",
        "records = []\n",
        "weak_streak = deque(maxlen=PROTOTYPE_SELECTION[\"patience_k\"])\n",
        "\n",
        "for proto in prototypes:\n",
        "    any_strong = False\n",
        "    for mode_name, cfg in MODES.items():\n",
        "        res = find_best_q_for_prototype(G, proto, cfg[\"binary\"], cfg[\"nominal\"], global_edges)\n",
        "        if res is None:\n",
        "            continue\n",
        "        qv = res[\"q\"]\n",
        "        records.append({\n",
        "            \"mode\": mode_name,\n",
        "            \"prototype\": res[\"prototype\"],\n",
        "            \"q\": qv,\n",
        "            \"q_rg\": res[\"q_rg\"],\n",
        "            \"rho\": res[\"rho\"],\n",
        "            \"sigma\": res[\"sigma\"],\n",
        "            \"n_out\": res[\"n_out\"],\n",
        "            \"n_binary\": len(cfg[\"binary\"]),\n",
        "            \"n_nominal\": len(cfg[\"nominal\"])\n",
        "        })\n",
        "        if qv >= PROTOTYPE_SELECTION[\"quality_threshold\"]:\n",
        "            any_strong = True\n",
        "    weak_streak.append(not any_strong)\n",
        "\n",
        "    # early-stop disabled while debugging unless you set threshold > 0\n",
        "    if (PROTOTYPE_SELECTION[\"quality_threshold\"] > 0 and\n",
        "        len(weak_streak) == PROTOTYPE_SELECTION[\"patience_k\"] and\n",
        "        all(weak_streak)):\n",
        "        print(f\"Early stop: last {PROTOTYPE_SELECTION['patience_k']} prototypes yielded weak q \"\n",
        "              f\"(< {PROTOTYPE_SELECTION['quality_threshold']}).\")\n",
        "        break\n",
        "\n",
        "# =========================\n",
        "# Reporting\n",
        "# =========================\n",
        "results = pd.DataFrame.from_records(records)\n",
        "if results.empty:\n",
        "    raise RuntimeError(\"No results produced. Most common cause: ID mismatch — check '[ID match]' and '[coverage]' lines above.\")\n",
        "\n",
        "summary = results.groupby(\"mode\").agg(\n",
        "    prototypes=(\"prototype\", \"nunique\"),\n",
        "    mean_q=(\"q\", \"mean\"),\n",
        "    std_q=(\"q\", \"std\"),\n",
        "    median_q=(\"q\", \"median\"),\n",
        "    mean_q_rg=(\"q_rg\", \"mean\")\n",
        ").reset_index().sort_values(\"mean_q\", ascending=False)\n",
        "\n",
        "print(\"\\n=== MODE SUMMARY ===\")\n",
        "print(summary.to_string(index=False))\n",
        "\n",
        "print(\"\\n=== BEST PROTOTYPES (top 20 by q) ===\")\n",
        "print(results.sort_values(\"q\", ascending=False).head(20).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D2gYbdmt_lb_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}